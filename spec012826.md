spec.md — Antigravity Agentic AI (WOW Workspace) 技術規格書（Technical Specification）

## 1. 文件目的與範圍

本文件描述「Antigravity Agentic AI — WOW Workspace」的完整技術規格與系統設計，對應目前的 `app.py`（單檔 Streamlit 應用）與 `requirements.txt`，並涵蓋以下能力：

1. WOW UI：Light/Dark 模式、20 種畫家風格（含 Jackpot 隨機）、雙語介面（EN / 繁體中文）。
2. API Key 管理：優先從環境變數讀取；若 ENV 不存在，允許在網頁輸入；若 ENV 存在則 UI 不顯示 key 值。
3. 文件輸入與關鍵字高亮：上傳多檔（Text/MD/PDF/CSV/JSON），預覽、關鍵字掃描高亮。
4. Agent Chain：從 `agents.yaml` 載入 Agents，支援 step-by-step 串接、每步可覆寫 model/max_tokens/temperature/prompt/system_prompt，並可手動編輯輸出作為下一步輸入。
5. AI Note Keeper：貼上文字/Markdown，透過 6 種 AI Magics 產出結構化筆記，並可進行 Q&A。
6. Distribution Visualization（新增頁籤）：支援貼上或上傳醫療器材配送資料（text/csv/json），若非標準化則轉為標準欄位；提供 5 張視覺化圖表（含可點擊節點的網路圖、Sankey 流向圖等）、多重篩選器、以及可自訂 prompt + 模型生成 1000–2000 字 Markdown 摘要；並支援在篩選後資料上執行 `agents.yaml` 的任一 Agent。

本系統部署目標為 Hugging Face Spaces（Streamlit runtime）。

---

## 2. 系統總覽（High-Level Architecture）

### 2.1 技術棧
- **UI/Server**：Streamlit（單一程序、狀態由 `st.session_state` 管理）
- **資料處理**：pandas
- **視覺化**：
  - Plotly（Sankey、時間序列、Top bars、Heatmap）
  - streamlit-agraph（可點擊節點的分布網路圖）
- **LLM 供應商**：
  - OpenAI（`openai` SDK）
  - Google Gemini（`google-generativeai`）
  - Anthropic（`anthropic`）
  - Grok/xAI（透過 OpenAI 相容介面 base_url `https://api.x.ai/v1`）

### 2.2 程式結構
- `app.py`：包含所有 UI、狀態、資料解析、標準化、視覺化、LLM 呼叫、Agents 執行等邏輯。
- `agents.yaml`：定義 Agents 列表（name/provider/model/system_prompt/prompt/temperature/max_tokens）。
- `requirements.txt`：依賴套件列表。
- 其餘文件如 `SKILL.md`（本規格不覆寫）。

### 2.3 執行模型
- Streamlit 每次互動會 rerun script；系統透過 `st.session_state` 保存：
  - UI 偏好（theme/lang/style）
  - API keys（僅當 ENV 缺失時）
  - 文件內容與高亮版本
  - Agent chain state（當前步驟、覆寫參數、上一輸出）
  - Note Keeper 內容
  - Distribution dataset（原始 text、標準化 DataFrame、資料集 prompt）
  - execution history log

---

## 3. WOW UI 規格

### 3.1 Theme / Style / Language
- 使用者可在 Sidebar 設定：
  - `theme_mode`: `dark` 或 `light`
  - `painter_style`: 20 種畫家風格之一，或使用 Jackpot 隨機
  - `lang`: `en` 或 `zh-TW`

### 3.2 CSS 注入策略
- 以 `_css(theme_mode, painter_style)` 動態產生 CSS（包含色票、背景 radial gradient、卡片樣式、按鈕風格、input 圓角等）。
- 每次 sidebar 選項變更後立即重新注入 CSS（確保 rerun 後樣式一致）。

### 3.3 WOW Header + Status Chips
Header 顯示：
- 主標題與副標題（依語言切換）
- 狀態 chips：
  - 當前 theme_mode 與 painter_style
  - 當前語言
  - Provider status（可用 keys 數 / 4）
  - Last run timestamp
- Keys status（OpenAI/Gemini/Anthropic/Grok）顯示 ✅ / —（僅顯示可用性，不顯示值）

---

## 4. API Key 管理規格（安全與體驗）

### 4.1 Key 來源優先序
- `get_api_key(env_var)`：
  1) 若 `os.environ[env_var]` 存在：回傳該值，並標記 `from_env=True`
  2) 否則使用 `st.session_state.ui_keys[env_var]`（使用者輸入），`from_env=False`

### 4.2 UI 顯示規則
- 若 key 來自環境變數：UI 顯示 “Loaded from environment (hidden)”
- 若 key 不存在：顯示 `st.text_input(type="password")` 供輸入
- 不將 key 寫入檔案，不回存 ENV，不輸出到 log

### 4.3 Provider 對應
- OpenAI：`OPENAI_API_KEY`
- Gemini：`GEMINI_API_KEY`
- Anthropic：`ANTHROPIC_API_KEY`
- Grok：`GROK_API_KEY`

---

## 5. LLM 呼叫與 Provider 路由

### 5.1 Model → Provider 推斷
`infer_provider(model)` 依 model 前綴決定 provider：
- `gpt-` → openai
- `gemini-` → gemini
- `claude-` → anthropic
- `grok-` → grok
- fallback → openai

### 5.2 統一 LLM 呼叫介面
`call_llm(provider, model, api_key, system_prompt, user_prompt, max_tokens, temperature)`：
- OpenAI：Chat Completions
- Gemini：GenerativeModel（system_instruction 盡可能傳入）
- Anthropic：messages API
- Grok：使用 OpenAI SDK + base_url 指向 xAI endpoint

回傳：
- `text`：模型輸出
- `meta`：包含 provider/model/max_tokens/temperature，部分 provider 若回 usage 則附加

### 5.3 Prompt 模板
- Agents prompt 支援 `{input}` 模板置換（`render_template`）。
- 若格式化失敗（缺少 key 等），回退原字串避免崩潰。

---

## 6. `agents.yaml` 與 Agent Chain 規格

### 6.1 Agents YAML Schema（讀寫）
- `load_agents_config()` 從 `agents.yaml` 載入到 session。
- Settings tab 提供 YAML editor：
  - `yaml.safe_load` 解析
  - validation：頂層需含 `agents` 且為 list
  - `save_agents_config()` 寫回 `agents.yaml`

### 6.2 Chain 執行模式
Chain 狀態存於 `st.session_state.chain_state`：
- `active`: bool
- `agents`: 選取的 agent name list
- `idx`: 當前步驟 index
- `current_input`: 當前輸入文字（可被使用者編輯）
- `last_output`: 上一步輸出
- `overrides`: per agent 覆寫參數 dict
- `auto`: bool（auto-run chain 模式）

### 6.3 每步可覆寫參數
UI 在每一步顯示：
- Model（下拉）
- max_tokens（數字）
- temperature（slider）
- system_prompt（text_area）
- prompt（text_area）
覆寫結果寫入 `chain_state.overrides[agent_name]`

### 6.4 Output-to-next（可編輯傳遞）
- 每個 agent 執行後：
  - 顯示 output（Markdown 或 Text）
  - 顯示 editable output text_area
  - 使用「Use edited output as next input」將 edited output 設為 `current_input` 並 idx+1

### 6.5 Execution log
每次執行記錄至 `st.session_state.execution_log`：
- ts、agent、output、meta
- Agents tab 額外記錄 estimated token（粗估）

---

## 7. 文件輸入（Workspace tab）規格

### 7.1 支援格式
- 上傳多檔：Text/MD/PDF/CSV/JSON
- `safe_read_uploaded()`：
  - PDF：抽取第 1 頁文字（pypdf / PyPDF2 fallback）
  - 其他：讀取 bytes → utf-8 decode（errors ignore）

### 7.2 Document preview & keyword highlight
- 每份 doc 以 expander 顯示 preview text_area
- 關鍵字掃描：
  - 使用者輸入 keyword list + color picker
  - `highlight_keywords_html()` 用 regex 將 keyword 包 `<span class="kw">`，以 `unsafe_allow_html=True` 顯示
  - 高亮結果存入 `processed_docs[f"{doc_name}__highlighted"]`

---

## 8. AI Note Keeper 規格

### 8.1 功能
- 輸入 note_text（raw text/markdown）
- 兩種檢視模式：
  - Markdown 模式：編輯 note_markdown 並 render
  - Text 模式：編輯 note_text

### 8.2 AI Magics（6 種）
- Formatting / Summary / Action Items / Flashcards / Translate：呼叫 LLM
- Keywords Highlight：使用者輸入 keywords + color，HTML preview

### 8.3 Ask on note
- 以 note_markdown 或 note_text 作為 context
- 單次 prompt → LLM → Markdown 回答
- 不維持多輪對話（若需可擴充）

---

## 9. Distribution Visualization（新增頁籤）規格

### 9.1 目標
提供「醫療器材配送/流向」資料的互動視覺化與分析摘要，支援：
- dataset ingestion（upload/paste/default）
- standardization（非標準→標準欄位）
- preview 20 records
- filters（date range / SupplierID / Category / LicenseNo / CustomerID，多選）
- 5 張圖（含可點擊節點的 network）
- 1000–2000 字繁中 Markdown 摘要（模型可選 + prompt 可改 + prompt 可綁定 dataset）
- 對篩選後資料執行 `agents.yaml` 任一 agent

### 9.2 資料輸入與標準化流程

#### 9.2.1 原始輸入來源
- file uploader：txt/csv/json
- text_area paste
- default dataset button（內建 CSV）

若上傳檔案存在，會覆寫 raw_text（以最新檔案內容為準）。

#### 9.2.2 解析（Parse）
`parse_dataset_text_to_df(raw)`：
- 若 raw 以 `{` 或 `[` 開頭：嘗試 `json.loads`
  - list → DataFrame(list)
  - dict → 若含 data/records/items/rows list，取該 list；否則 DataFrame(dict)
- 否則視為 CSV/TSV
  - delimiter auto-detect：tab 比逗號多則使用 `\t`
  - `pd.read_csv(StringIO(raw))`

#### 9.2.3 標準化（Standardize）
`standardize_distribution_df(df)`：
- 欄位映射：對每個原始欄位做 normalize（小寫、底線、去掉非字元），透過 `SYNONYMS` 對應至標準欄位
- 補齊標準欄位：缺的欄位補 `None`
- 額外欄位保留於 `_extras`（record-level dict），以免資訊丟失
- 型態處理：
  - `Deliverdate_dt`：將 Deliverdate 轉 datetime（支援 YYYYMMDD 與一般日期字串）
  - `Number`：轉 numeric；缺失預設 1；轉 int
  - 其餘字串欄位：轉 str、去 nan/None、strip
- 清理全空 key rows：若 SupplierID/CustomerID/LicenseNo/Category 全空則移除

#### 9.2.4 Preview
- 使用 `df_preview_markdown(df, n=20)` 顯示前 20 筆標準欄位。

### 9.3 篩選器（Filters）
`apply_filters(df, date_range, supplier_ids, categories, license_nos, customer_ids)`：
- date_range（若 Deliverdate_dt 有效）：
  - Streamlit date_input 回傳 start/end，轉 Timestamp
  - 篩選 `Deliverdate_dt` 在範圍內
- 多選欄位篩選：`col.isin(selected_list)`
- filters 作用於視覺化與摘要、agent input 的同一份 df_f（filtered df）

### 9.4 視覺化（5 Graphs）

#### 9.4.1 Graph 1：Distribution Network（click nodes）
- 目標：呈現 Supplier→Category→License→Customer 的網路結構
- 建構：
  - 先計算每層 top N（預設每層 60，依 Number 加總排序）
  - 篩掉非 top 節點以控制圖大小
  - 建 3 組 edges：
    - SupplierID → Category
    - Category → LicenseNo
    - LicenseNo → CustomerID
- 渲染：
  - streamlit-agraph：
    - directed, hierarchical, physics=False
    - 可點擊節點：`selected = agraph(...)`
- 點擊節點後的資訊面板：
  - `node_info(df_f, node_id)`：顯示 records、units、Top counterparts（Top5 supplier/customer/category/license）

#### 9.4.2 Graph 2：Sankey Flow
- 目標：呈現 Supplier→Category→License→Customer 的流量大小
- 以 groupby 聚合 `Number`，並限制 top 300 路徑（避免渲染過慢）
- Plotly go.Sankey

#### 9.4.3 Graph 3：Time Series
- 目標：呈現每日 records 與 units（Number sum）
- 以 Deliverdate_dt 日粒度 groupby
- Plotly Scatter，雙 y-axis（records vs units）

#### 9.4.4 Graph 4：Top Entities（兩張 bar）
- Top SupplierID（units）
- Top CustomerID（units）
- Plotly Express bar，各取 top 12

#### 9.4.5 Graph 5：Heatmap（Supplier × Category）
- pivot_table：index SupplierID、columns Category、values Number sum
- 控制矩陣大小：取 top 20 suppliers 與 top 20 categories
- Plotly Express imshow

### 9.5 摘要生成（1000–2000 字，Markdown）

#### 9.5.1 Prompt 管理（Keep prompt on dataset）
- 以 `dist_dataset_name` 作 key
- 存在 `st.session_state.dist_prompt_by_dataset[dataset_name]`
- UI 提供「Keep prompt」按鈕將編輯後 prompt 綁定該 dataset_name（僅 session）

#### 9.5.2 模型選擇
- summary 模型限定：
  - `gemini-2.5-flash`
  - `gemini-3-flash-preview`
  - `gpt-4o-mini`
- provider 依 model 推斷，選用對應 API key

#### 9.5.3 輸入內容（避免巨量 token）
系統不直接把完整 df_f 丟入模型，而是提供：
- 統計摘要 JSON：`dataset_stats_pack(df_f)`
  - records、date_min/max、units_total、supplier/customer/category/license counts
  - top lists（top suppliers/customers/categories/licenses）
  - `sample_20_records`：前 20 筆標準欄位 records
- 使用者 prompt（可改）
- system prompt 指示「嚴謹、不臆測、繁中」

#### 9.5.4 輸出與編輯
- 摘要輸出存 `st.session_state.dist_summary_md`
- UI 提供 editable text_area（Summary editable）與 Markdown render
- 摘要生成也會寫入 execution_log（agent="Distribution-Summary"）

### 9.6 在篩選後資料上執行 Agents
- 使用者選擇 `agents.yaml` 的 agent name
- 可選擇 model override（限定同 summary 模型集合或使用 agent default）
- Agent input 組合：
  - dataset name
  - filtered record count
  - stats JSON（同 dataset_stats_pack）
  - 前 50 筆 Markdown table（標準欄位）
- 執行方式：
  - `run_agent(agent_conf, agent_input, overrides, resolved_keys)`
- 結果輸出為 Markdown，並記錄 execution_log

---

## 10. 可靠性、效能與限制

### 10.1 Streamlit rerun 特性
- 任何互動皆 rerun；需依賴 session_state 保存狀態。
- 大型資料渲染成本高，建議：
  - Network/Sankey 限制節點/路徑數量（現已做）
  - Heatmap 限制矩陣大小（top 20×20）
  - Preview 僅顯示前 20 或 50 筆

### 10.2 資料規模預期
- 若資料量很大（> 100k rows）：
  - pandas groupby/pivot 可能變慢
  - 建議未來可加入抽樣、快取（st.cache_data）、或以 DuckDB/Polars 替代

### 10.3 LLM 成本控制
- 摘要生成不輸入全量資料，改以統計摘要 JSON 降低 token 成本。
- 仍可能因 prompt 或模型輸出過長而超限；目前 max_tokens 對 summary 固定較保守（如 7000）。

### 10.4 PDF 解析限制
- PDF 若無可抽取文字（掃描影像），會失敗或得到空字串；未含 OCR。

---

## 11. 安全性與隱私

- API keys 不回寫、不顯示（若來自 ENV）。
- 任何上傳資料都可能包含敏感資訊；系統會送入 LLM（若使用者執行 agent/summary）。
- 建議未來加入：
  - 欄位遮罩（CustomerID/SerNo/UDID 等）選項
  - 明確的資料使用告知與同意提示
- HTML 高亮使用 `unsafe_allow_html=True`，風險控制：
  - 系統對內容做基本 HTML escape，再插入標記（避免任意 HTML 注入）。

---

## 12. 部署與運維（Hugging Face Spaces）

### 12.1 部署方式
- Hugging Face Space 類型：Streamlit
- 必要檔案：`app.py`, `requirements.txt`, `agents.yaml`
- Key 注入：
  - 透過 HF Spaces Secrets / environment variables 設定 `OPENAI_API_KEY` 等
  - 使用者亦可在 UI 輸入（session 內）

### 12.2 依賴
- 需安裝 plotly、streamlit-agraph、pandas 等（見 requirements.txt）
- pypdf/PyPDF2 為 PDF 解析 fallback

### 12.3 可觀測性
- execution_log 存於 session_state（不持久化）
- 若需跨 session 的追蹤需外部 storage（目前未設計）

---

## 13. 測試策略（建議）

### 13.1 單元測試（可選）
由於 Streamlit app.py 單檔，建議抽出純函數測試：
- parse_dataset_text_to_df：測 CSV/TSV/JSON envelope
- standardize_distribution_df：測 synonyms mapping、Number coercion、date parsing、_extras 保留
- apply_filters：測多選與日期篩選邏輯
- build_network_graph：測節點/邊數與穩定性（小樣本）

### 13.2 整合測試（手動/半自動）
- 不同 provider key 缺失時的錯誤提示
- Distribution tab：
  - 上傳 CSV/JSON
  - 標準化後 schema 正確
  - filters 能聯動 5 張圖
  - node click 顯示 info
  - summary 生成成功並可編輯

---

## 14. 擴充性（Roadmap 建議）

- 增加更多 filters（UDID/Model/DeviceNAME/LotNO/SerNo）
- 增加 export（下載標準化資料、篩選後資料、摘要 markdown、圖表 png/html）
- 加入 st.cache_data 快取 groupby 計算
- 加入 OCR（tesseract/vision API）處理掃描 PDF
- Network 圖加入節點數/權重指標選項（units vs records）
- 多輪對話式 Note Keeper（保留 conversation history）

---

## 15. 使用者流程摘要（End-to-End）

1) 使用者在 Sidebar 選擇主題（Light/Dark）、語言（EN/繁中）、畫家風格（可 Jackpot）。
2) 在 Workspace 上傳文件並 preview，可進行 keyword highlight。
3) 在 Agents tab 選擇上下文（文件或手動貼上），選定 agents 串接，逐步執行並可編輯輸出傳遞。
4) 在 Distribution tab 上傳/貼上/載入預設配送資料 → Standardize → preview 20 筆 → filters → 5 張圖互動探索 → 產生 1000–2000 字摘要（可改 prompt + 模型） → 針對篩選後資料跑指定 agent。
5) 在 Note Keeper tab 進行筆記整理與延伸問答。
6) 在 History tab 回看執行紀錄與輸出。
7) 在 Settings tab 編輯 agents.yaml 以調整/擴充 agent 行為。

---

# 20 follow-up questions

1. 你希望 Distribution tab 的「標準化」在欄位不足時自動呼叫 LLM 來推斷欄位對應（例如 user 上傳欄位名為中文）嗎？
2. `Deliverdate` 除了 YYYYMMDD，你是否需要支援民國年或自訂格式（例如 2025/11/07、2025.11.07）並在 UI 提供格式提示？
3. 是否需要加入「資料下載」功能：下載標準化後 CSV、篩選後 CSV、摘要 Markdown、以及 Plotly 圖表？
4. Network 圖的節點數限制（每層 Top 60）是否要改成 UI 可調（例如 20/60/120/300）？
5. Sankey 的 Top 300 路徑限制是否要改成 UI 可調，並提供「依 units/records」切換？
6. 是否要在 Distribution tab 增加「UDID/Model/DeviceNAME/LotNO/SerNo」的多選篩選器（目前僅 4 欄）？
7. 是否要增加「缺漏率面板」：各欄位缺漏百分比、Top 缺漏欄位、缺漏隨時間變化？
8. 你希望摘要固定繁中，還是要跟 UI 語言同步（EN/繁中切換）？
9. 摘要現在用 stats JSON + sample records，你是否希望加入更多聚合（例如每月、每供應商×類別交叉表）以提升摘要品質？
10. 是否需要在 Distribution tab 新增「明細表」：可搜尋、排序、分頁顯示篩選後資料？
11. 是否需要在 node click 的資訊卡加入「相關節點鑽取」：點 Supplier 直接生成其子樹（Category→License→Customer）的局部網路？
12. 你希望 Agent run on dataset 也支援像 Agents tab 一樣的 step-by-step chain（多 agents 串接、可編輯傳遞）嗎？
13. 你希望 Distribution tab 的 agent 執行也允許覆寫 prompt/system_prompt/max_tokens/temperature（目前只提供 model override）嗎？
14. 是否需要加入「敏感資訊遮罩」選項（例如 CustomerID/SerNo/UDID 哈希或部分遮罩）再送入 LLM？
15. execution_log 目前只存在 session，是否要提供匯出成 JSON/Markdown、或接外部 storage（S3/DB）？
16. 是否需要加入「成本估算」面板：依 provider/model 推估 token 成本並顯示在 dashboard？
17. 是否要為視覺化加入「自動洞察」：例如偵測集中度過高（Top1 占比）、某供應商突增等自動提示？
18. 是否需要支援多資料集管理：在 Distribution tab 保存多個 dataset（清單、切換、刪除）而不是單一 dist_df？
19. 你希望 `agents.yaml` 增加 UI metadata（icon、category、default_view）以在 Distribution/Agents tab 更好分組呈現嗎？
20. 對 Hugging Face Spaces 的資源限制，你希望我提出一份「效能最佳化版本規格」（cache、節點抽樣、圖表降採樣、延遲載入）嗎？
2m24s
53.4kt
6,040t
選択されていません
Chat with your prompt...
選択されていません
